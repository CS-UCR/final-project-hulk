{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Team Hulk Project\n",
    "\n",
    "For our project, we looked into getting datasets on the usage of the word “Donald Trump” within social media messages. Most notably, messages from the social media platform Twitter, commonly referred to as \"tweets\". We focused on tweets that discuss the 45th President of the United States Donald J. Trump.\n",
    "\n",
    "We used the Twitter API to gather data from tweets relating to the President. From there, we will look into the correlation of the tweets based on when they are posted, such as the difference between tweets during specific times during the day.\n",
    "\n",
    "The Tweepy app was used to get json formatted data into python. This allowed us to use pandas library and follow the notebook on extracting data from json files to conduct our analysis.\n",
    "\n",
    "(part1) api, eda, cleaning (what you will probably say in presentation)\n",
    "\n",
    "mention your parts then mention my parts or whoever is first, my parts are about (which hashtags were trending about trump throughout the day.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "tweets = []\n",
    "for line in open('realData.json', 'r'):\n",
    "    tweets.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A total of 367,819 tweets were collected in a 2.3GB json file. A sample of the data looked something like this: \n",
    "![](jsonSS.png)\n",
    "\n",
    "After entering all of the data we gathered, we json_normalized our data into a pandas dataframe. There were over 400 columns of data per tweet (over 147 million cells!), however many of them were dropped due to the columns containing nullified NaN data or due to the columns pertaining to information outside the scope of our project. We utilized the df.drop method because we were not sure if there was a faster way to parse through each of the 400 normalized columns in our dataframe. In light of all this, our data cleaning looked like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Cleaning\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt #visualisation \n",
    "sns.set(color_codes=True)\n",
    "\n",
    "from pandas.io.json import json_normalize\n",
    "pd.set_option('display.max_columns', None)\n",
    "jsonData = json_normalize(tweets)\n",
    "jsonData = jsonData.drop(columns=[\"contributors\", \"coordinates\", \"display_text_range\", \"entities.media\", \"entities.symbols\", \"entities.urls\", \"extended_tweet.full_text\", \"extended_entities.media\", \"extended_tweet.display_text_range\", \"extended_tweet.entities.hashtags\", \"extended_tweet.entities.media\", \"extended_tweet.entities.urls\", \"extended_tweet.entities.symbols\", \"extended_tweet.entities.user_mentions\", \"extended_tweet.extended_entities.media\"])\n",
    "jsonData = jsonData.drop(columns=[\"favorited\", \"favorite_count\", \"filter_level\", \"geo\", \"id\", \"id_str\", \"in_reply_to_screen_name\", \"in_reply_to_status_id\", \"in_reply_to_status_id_str\", \"in_reply_to_user_id\", \"in_reply_to_user_id_str\"])\n",
    "jsonData = jsonData.drop(columns=[\"place\", \"place.bounding_box.coordinates\", \"place.bounding_box.type\", \"place.country\", \"place.country_code\", \"place.full_name\", \"place.id\", \"place.name\", \"place.place_type\", \"place.url\", \"possibly_sensitive\"])\n",
    "jsonData = jsonData.drop(columns=[\"quote_count\", \"quoted_status.contributors\", \"quoted_status.coordinates\", \"quoted_status.created_at\", \"quoted_status.display_text_range\", \"quoted_status.entities.hashtags\", \"quoted_status.entities.media\", \"quoted_status.entities.symbols\", \"quoted_status.entities.urls\", \"quoted_status.entities.user_mentions\", \"quoted_status.extended_entities.media\", \"quoted_status.extended_tweet.display_text_range\", \"quoted_status.extended_tweet.entities.hashtags\", \"quoted_status.extended_tweet.entities.media\", \"quoted_status.extended_tweet.entities.symbols\", \"quoted_status.extended_tweet.entities.urls\", \"quoted_status.extended_tweet.entities.user_mentions\", \"quoted_status.extended_tweet.extended_entities.media\", \"quoted_status.extended_tweet.full_text\", \"quoted_status.favorite_count\", \"quoted_status.filter_level\", \"quoted_status.geo\", \"quoted_status.favorited\", \"quoted_status.id\", \"quoted_status.id_str\", \"quoted_status.in_reply_to_screen_name\", \"quoted_status.in_reply_to_status_id\", \"quoted_status.in_reply_to_status_id_str\", \"quoted_status.in_reply_to_user_id\", \"quoted_status.in_reply_to_user_id_str\", \"quoted_status.is_quote_status\", \"quoted_status.lang\", \"quoted_status.place\", \"quoted_status.possibly_sensitive\", \"quoted_status.quote_count\", \"quoted_status.reply_count\", \"quoted_status.retweet_count\", \"quoted_status.retweeted\", \"quoted_status.source\", \"quoted_status.text\", \"quoted_status.truncated\"])\n",
    "jsonData = jsonData.drop(columns=[\"quoted_status.user.contributors_enabled\", \"quoted_status.user.created_at\", \"quoted_status.user.default_profile\", \"quoted_status.user.default_profile_image\", \"quoted_status.user.description\", \"quoted_status.user.favourites_count\", \"quoted_status.user.follow_request_sent\", \"quoted_status.user.followers_count\", \"quoted_status.user.following\", \"quoted_status.user.friends_count\", \"quoted_status.user.geo_enabled\", \"quoted_status.user.id\", \"quoted_status.user.id_str\", \"quoted_status.user.is_translator\", \"quoted_status.user.lang\", \"quoted_status.user.listed_count\", \"quoted_status.user.location\", \"quoted_status.user.name\", \"quoted_status.user.notifications\", \"quoted_status.user.profile_background_color\", \"quoted_status.user.profile_background_image_url\", \"quoted_status.user.profile_background_image_url_https\", \"quoted_status.user.profile_background_tile\", \"quoted_status.user.profile_banner_url\", \"quoted_status.user.profile_image_url\", \"quoted_status.user.profile_image_url_https\", \"quoted_status.user.profile_link_color\", \"quoted_status.user.profile_sidebar_border_color\", \"quoted_status.user.profile_sidebar_fill_color\", \"quoted_status.user.profile_text_color\", \"quoted_status.user.profile_use_background_image\", \"quoted_status.user.protected\", \"quoted_status.user.screen_name\", \"quoted_status.user.statuses_count\", \"quoted_status.user.time_zone\", \"quoted_status.user.translator_type\", \"quoted_status.user.url\", \"quoted_status.user.utc_offset\", \"quoted_status.user.verified\", \"quoted_status_id\", \"quoted_status_id_str\", \"quoted_status_permalink.display\", \"quoted_status_permalink.url\", \"quoted_status_permalink.expanded\"])\n",
    "jsonData = jsonData.drop(columns=[\"reply_count\", \"retweet_count\", \"retweeted\", \"retweeted_status.contributors\", \"retweeted_status.coordinates\", \"retweeted_status.display_text_range\", \"retweeted_status.entities.hashtags\", \"retweeted_status.entities.media\", \"retweeted_status.entities.symbols\", \"retweeted_status.entities.urls\", \"retweeted_status.entities.user_mentions\", \"retweeted_status.extended_entities.media\", \"retweeted_status.extended_tweet.entities.hashtags\", \"retweeted_status.extended_tweet.entities.media\", \"retweeted_status.extended_tweet.entities.symbols\", \"retweeted_status.extended_tweet.entities.urls\", \"retweeted_status.extended_tweet.entities.user_mentions\", \"retweeted_status.extended_tweet.display_text_range\", \"retweeted_status.extended_tweet.extended_entities.media\", \"retweeted_status.extended_tweet.extended_entities.media\", \"retweeted_status.favorited\", \"retweeted_status.filter_level\", \"retweeted_status.geo\", \"retweeted_status.id\", \"retweeted_status.id_str\", \"retweeted_status.in_reply_to_screen_name\", \"retweeted_status.in_reply_to_status_id\", \"retweeted_status.in_reply_to_status_id_str\", \"retweeted_status.in_reply_to_user_id\", \"retweeted_status.in_reply_to_user_id_str\", ])\n",
    "jsonData = jsonData.drop(columns=[\"retweeted_status.place\", \"retweeted_status.place.bounding_box.coordinates\", \"retweeted_status.place.bounding_box.type\", \"retweeted_status.place.country\", \"retweeted_status.place.country_code\", \"retweeted_status.place.full_name\", \"retweeted_status.place.id\", \"retweeted_status.place.name\", \"retweeted_status.place.place_type\", \"retweeted_status.place.url\", \"retweeted_status.possibly_sensitive\", \"retweeted_status.quoted_status.contributors\", \"retweeted_status.quoted_status.coordinates\", \"retweeted_status.quoted_status.created_at\", \"retweeted_status.quoted_status.display_text_range\", \"retweeted_status.quoted_status.entities.hashtags\", \"retweeted_status.quoted_status.entities.media\", \"retweeted_status.quoted_status.entities.symbols\", \"retweeted_status.quoted_status.entities.urls\", \"retweeted_status.quoted_status.entities.user_mentions\", \"retweeted_status.quoted_status.extended_entities.media\", \"retweeted_status.quoted_status.extended_tweet.display_text_range\", \"retweeted_status.quoted_status.extended_tweet.entities.hashtags\", \"retweeted_status.quoted_status.extended_tweet.entities.media\", \"retweeted_status.quoted_status.extended_tweet.entities.symbols\", \"retweeted_status.quoted_status.extended_tweet.entities.urls\", \"retweeted_status.quoted_status.extended_tweet.entities.user_mentions\", \"retweeted_status.quoted_status.extended_tweet.extended_entities.media\"])\n",
    "jsonData = jsonData.drop(columns=[\"retweeted_status.quoted_status.extended_tweet.full_text\", \"retweeted_status.quoted_status.favorite_count\", \"retweeted_status.quoted_status.favorited\", \"retweeted_status.quoted_status.filter_level\", \"retweeted_status.quoted_status.geo\", \"retweeted_status.quoted_status.id\", \"retweeted_status.quoted_status.id_str\", \"retweeted_status.quoted_status.in_reply_to_screen_name\", \"retweeted_status.quoted_status.in_reply_to_status_id\", \"retweeted_status.quoted_status.in_reply_to_status_id_str\", \"retweeted_status.quoted_status.in_reply_to_user_id\", \"retweeted_status.quoted_status.in_reply_to_user_id_str\", \"retweeted_status.quoted_status.is_quote_status\", \"retweeted_status.quoted_status.lang\", \"retweeted_status.quoted_status.place\", \"retweeted_status.quoted_status.possibly_sensitive\", \"retweeted_status.quoted_status.quote_count\", \"retweeted_status.quoted_status.reply_count\", \"retweeted_status.quoted_status.retweeted\", \"retweeted_status.quoted_status.source\", \"retweeted_status.quoted_status.text\", \"retweeted_status.quoted_status.truncated\", \"retweeted_status.quoted_status.retweet_count\"])\n",
    "jsonData = jsonData.drop(columns=[\"retweeted_status.quoted_status.user.contributors_enabled\", \"retweeted_status.quoted_status.user.created_at\", \"retweeted_status.quoted_status.user.default_profile\", \"retweeted_status.quoted_status.user.default_profile_image\", \"retweeted_status.quoted_status.user.description\", \"retweeted_status.quoted_status.user.favourites_count\", \"retweeted_status.quoted_status.user.follow_request_sent\", \"retweeted_status.quoted_status.user.followers_count\", \"retweeted_status.quoted_status.user.following\", \"retweeted_status.quoted_status.user.friends_count\", \"retweeted_status.quoted_status.user.geo_enabled\", \"retweeted_status.quoted_status.user.id\", \"retweeted_status.quoted_status.user.id_str\", \"retweeted_status.quoted_status.user.is_translator\", \"retweeted_status.quoted_status.user.lang\", \"retweeted_status.quoted_status.user.listed_count\", \"retweeted_status.quoted_status.user.location\", \"retweeted_status.quoted_status.user.name\", \"retweeted_status.quoted_status.user.notifications\"])\n",
    "jsonData = jsonData.drop(columns=[\"retweeted_status.quoted_status.user.profile_background_color\", \"retweeted_status.quoted_status.user.profile_background_image_url\", \"retweeted_status.quoted_status.user.profile_background_image_url_https\", \"retweeted_status.quoted_status.user.profile_background_tile\", \"retweeted_status.quoted_status.user.profile_banner_url\", \"retweeted_status.quoted_status.user.profile_image_url\", \"retweeted_status.quoted_status.user.profile_image_url_https\", \"retweeted_status.quoted_status.user.profile_link_color\", \"retweeted_status.quoted_status.user.profile_sidebar_border_color\", \"retweeted_status.quoted_status.user.profile_sidebar_fill_color\", \"retweeted_status.quoted_status.user.profile_text_color\", \"retweeted_status.quoted_status.user.profile_use_background_image\", \"retweeted_status.quoted_status.user.protected\", \"retweeted_status.quoted_status.user.screen_name\", \"retweeted_status.quoted_status.user.statuses_count\", \"retweeted_status.quoted_status.user.time_zone\", \"retweeted_status.quoted_status.user.translator_type\", \"retweeted_status.quoted_status.user.url\", \"retweeted_status.quoted_status.user.utc_offset\", \"retweeted_status.quoted_status.user.verified\", \"retweeted_status.quoted_status_id\", \"retweeted_status.quoted_status_id_str\", \"retweeted_status.quoted_status_permalink.display\", \"retweeted_status.quoted_status_permalink.expanded\", \"retweeted_status.quoted_status_permalink.url\"])\n",
    "jsonData = jsonData.drop(columns=[\"retweeted_status.user.default_profile\", \"retweeted_status.user.profile_background_color\", \"retweeted_status.user.following\", \"retweeted_status.user.id\", \"retweeted_status.user.id_str\", \"retweeted_status.user.is_translator\", \"retweeted_status.user.lang\", \"retweeted_status.user.notifications\", \"retweeted_status.user.profile_background_image_url\", \"retweeted_status.user.profile_background_image_url_https\", \"retweeted_status.user.profile_background_tile\", \"retweeted_status.user.profile_banner_url\", \"retweeted_status.user.profile_image_url_https\", \"retweeted_status.user.profile_link_color\", \"retweeted_status.user.profile_sidebar_border_color\", \"retweeted_status.user.profile_sidebar_fill_color\", \"retweeted_status.user.profile_text_color\", \"retweeted_status.user.profile_use_background_image\", \"retweeted_status.user.protected\", \"retweeted_status.user.follow_request_sent\", \"retweeted_status.user.profile_image_url\"])\n",
    "jsonData = jsonData.drop(columns=[\"retweeted_status.user.time_zone\", \"retweeted_status.user.translator_type\", \"retweeted_status.user.url\", \"retweeted_status.user.utc_offset\", \"retweeted_status.user.default_profile_image\", \"retweeted_status.user.contributors_enabled\"])\n",
    "jsonData = jsonData.drop(columns=[\"source\", \"timestamp_ms\", \"truncated\"])\n",
    "jsonData = jsonData.drop(columns=[\"user.default_profile_image\", \"user.contributors_enabled\", \"user.id\", \"user.id_str\", \"user.is_translator\", \"user.following\", \"user.follow_request_sent\", \"user.lang\", \"user.notifications\", \"user.profile_text_color\", \"user.protected\", \"user.profile_background_color\", \"user.profile_use_background_image\", \"user.profile_background_image_url\", \"user.profile_background_image_url_https\", \"user.profile_background_tile\", \"user.profile_banner_url\", \"user.profile_image_url\", \"user.profile_image_url_https\", \"user.profile_link_color\", \"user.profile_sidebar_border_color\", \"user.profile_sidebar_fill_color\", \"user.time_zone\", \"user.translator_type\", \"user.url\", \"user.utc_offset\"])\n",
    "#For test data only\n",
    "jsonData = jsonData.drop(columns=[\"coordinates.coordinates\", \"coordinates.type\", \"geo.coordinates\", \"geo.type\", \"quoted_status.coordinates.coordinates\", \"quoted_status.coordinates.type\", \"quoted_status.geo.coordinates\", \"quoted_status.geo.type\", \"quoted_status.place.bounding_box.coordinates\", \"quoted_status.place.bounding_box.type\", \"quoted_status.place.country\", \"quoted_status.place.country_code\", \"quoted_status.place.full_name\", \"quoted_status.place.id\", \"quoted_status.place.name\", \"quoted_status.place.place_type\", \"quoted_status.place.url\", \"quoted_status.quoted_status_id\", \"quoted_status.quoted_status_id_str\", \"quoted_status.scopes.followers\", \"retweeted_status.coordinates.coordinates\", \"retweeted_status.coordinates.type\", \"retweeted_status.geo.coordinates\", \"retweeted_status.geo.type\", \"retweeted_status.quoted_status.place.bounding_box.coordinates\", \"retweeted_status.quoted_status.place.bounding_box.type\", \"retweeted_status.quoted_status.place.country\", \"retweeted_status.quoted_status.place.country_code\", \"retweeted_status.quoted_status.place.full_name\", \"retweeted_status.quoted_status.place.id\", \"retweeted_status.quoted_status.place.name\", \"retweeted_status.quoted_status.place.place_type\", \"retweeted_status.quoted_status.place.url\", \"retweeted_status.quoted_status.quoted_status_id\", \"retweeted_status.quoted_status.quoted_status_id_str\", \"retweeted_status.scopes.followers\", \"retweeted_status.withheld_in_countries\", \"withheld_in_countries\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trending Tweets About President Trump Throughout the Day\n",
    "\n",
    "In order to parse through the hashtags, we needed to clean up the data and make it more presentable to a reader. Here is some of the cleanup we did just to be able to parse through valid hashtags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsonData['entities.hashtags'] = jsonData['entities.hashtags'].astype(str)\n",
    "jsonData['entities.hashtags'] = jsonData['entities.hashtags'].str.replace(r\"\\{u\\'[a-z]*\\':\\s\\[[0-9]*,\\s[0-9]*\\]\", \"\") #Deletes useless words ( u'indicies': ' )\n",
    "jsonData['entities.hashtags'] = jsonData['entities.hashtags'].str.replace(r\",\\su\\'[a-z]*\\':\\su\\'\", \"\") #Same as above BUT for indicies that comes after\n",
    "jsonData['entities.hashtags'] = jsonData['entities.hashtags'].str.replace(r\"\\}\", \"\") #Deletes stray close curly brackets from first replace function ( } )\n",
    "jsonData['entities.hashtags'] = jsonData['entities.hashtags'].str.replace(r\"\\[\\]\", \"\") #Deletes stray \"no hashtags\" written as brackets ( [] ) \n",
    "jsonData['entities.hashtags'] = jsonData['entities.hashtags'].str.replace(r\"\\'*\", \"\") #Delets stray quote marks ( ' )\n",
    "jsonData['entities.hashtags'] = jsonData['entities.hashtags'].str.replace(r\",\\s[a-zA-Z]*\", \"\") #Deletes multiple hashtags\n",
    "jsonData['entities.hashtags'] = jsonData['entities.hashtags'].str.replace(r\"\\[\", \"\") #Deletes the open bracket in the beginning\n",
    "jsonData['entities.hashtags'] = jsonData['entities.hashtags'].str.replace(r\"\\]\", \"\") #Deletes the close bracket in the end\n",
    "dataHashTags = jsonData[jsonData['entities.hashtags'] != ''] #Removes blank hashtag indicator that was left from replace function\n",
    "dataHashTags['entities.hashtags'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only 24,820 out of 367,819 tweets (~6.7%) contained any kind of hashtag. We decided to dig deeper into the hashtags that trended when mentioning the words \"Donald Trump\". The next block counts the total amount of unique hashtags that were used when mentioning President Trump. As you can see, #TrumpThreatensAmerica was mentioned 3518 times followed up by #DemocratsStandTall for 2828 times. These two hashtags made up the majority of the hashtags that were in our dataset. \n",
    "\n",
    "An interesting thing to note is that there is a total of 134 hashtags of \\u06a9\\u067e\\u062a... and so on. According to Twitter's Developer API Docs, they are the result of errors most likely from the conversion between Twitter data and json format. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mostUsedHashtag = dataHashTags['entities.hashtags'].value_counts()\n",
    "mostUsedHashtag = mostUsedHashtag.sort_values(ascending=False)\n",
    "mostUsedHashtag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a graphical representation of the information above.\n",
    "\n",
    "An interesting thing to note in this graph is that during the Covid-19 Coronavirus pandemic, the hashtag #COVID19 was ranked 23rd out of the most used hashtag when mentioning \"Donald Trump\".\n",
    "\n",
    "The hashtag #LinkinPark outranked #COVID19, ranking 19th overall when mentioning \"Donald Trump\". We were surprised by this at first and researched why the band LinkinPark was trending with the President's name, as the two entities are not commonly associated with each other. We discovered that during the data collection phase, the band LinkinPark had gone forward in the process to sue President Trump through the United States Courts due to unauthorized use of their song \"In The End\" in one of his campaign advertisements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "mostUsedHashtag.nlargest(23).plot.barh(fontsize = 15, figsize = (20,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get a better idea of trending hashtags that mentioned President Trump, we decided to split up the data into 4 time slots; Morning, Noon, Night, Overnight. However, we ran into a problem because the time the tweets were created were given to us in this format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsonTime = jsonData.copy()\n",
    "jsonTime.created_at[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To fix this, we had to clean this column by using the .str.replace() method. Since we have knowledge in regexs already, deleting excess string and converting the column into an int was a breeze. Now the time was in this format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsonTime['created_at'] = jsonTime['created_at'].str.replace(r\"[a-zA-Z]*\\s[a-zA-Z]*\\s[0-9]*\", \"\") #Deletes the day and month since it's not needed in this observation\n",
    "jsonTime['created_at'] = jsonTime['created_at'].str.replace(r\"\\+(0000)*\\s\", \"\") #Deletes +0000, don't know why it's there but recorded time is +7hr from PST\n",
    "jsonTime['created_at'] = jsonTime['created_at'].str.replace(r\"(2020)*\", \"\") #Deletes year since we will always be in 2020 right now\n",
    "jsonTime['created_at'] = jsonTime['created_at'].str.replace(\":\", \"\") #Clean stray colons ( : )\n",
    "jsonTime['created_at'] = jsonTime['created_at'].astype(int) #Convert to int so we can compare values\n",
    "jsonTime.created_at[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, this format of hh:mm:ss was still 7 hours ahead of our timezone, Pacific Time (PST). To fix this, we had to convert the time. Unfortunately, you cannot simply subtract 7 hours from the time, otherwise you will end up with negative time. This was solved by adding 24 hours, or an additional day, followed by subtracting 7 hours and modding the number by 24 hours again. We were able to end up with the data like this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note that time is formatted in hh:mm:ss (h for hours, m for minutes, s for seconds).\n",
    "jsonTime['created_at'] = (jsonTime['created_at'] + 240000 - 70000) % 240000 #Add 24hrs then subtract 7hrs then mod by 24hrs so we don't get negative hours when converting to PST\n",
    "jsonTime.created_at[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we have to split the 4 time slots into their own category. Morning (6am-11am), Noon (11am-2pm), Night (6pm-12am), Overnight (12am-6am).\n",
    "\n",
    "NOTE: WE COLLECTED DATA FROM 5pm TO 1pm THE NEXT DAY. THEREFORE, WE ARE MISSING 4hrs OF DATA SO THERE WILL BE A SLIGHT BIAS IN THE NOON SECTION. WE APOLOGIZE FOR THIS POTENTIAL DISCREPANCY."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mornings = jsonTime[(jsonTime['created_at'] >= 130000) & (jsonTime['created_at'] < 180000)]\n",
    "mornings['estTime'] = \"Morning (6am-11am)\"\n",
    "\n",
    "noon = jsonTime[(jsonTime['created_at'] <= 10000) | (jsonTime['created_at'] >= 180000)]\n",
    "noon['estTime'] = \"Noon (11am-2pm)\"\n",
    "\n",
    "night = jsonTime[(jsonTime['created_at'] < 70000) & (jsonTime['created_at'] > 10000)]\n",
    "night['estTime'] = \"Night (6pm-12am)\"\n",
    "\n",
    "overnight = jsonTime[(jsonTime['created_at'] >= 70000) & ((jsonTime['created_at'] < 130000)) ]\n",
    "overnight['estTime'] = \"Overnight (12am-6am)\"\n",
    "\n",
    "tempTime = mornings.append(noon).append(night).append(overnight) #Takes soooooo long\n",
    "#tempTime.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: We are ignoring any warnings generated. We enjoy living on the edge.\n",
    "\n",
    "Despite the 4 hours missing from Noon, it was the second highest in terms of tweets per time slot. An interesting thing to note is that a lot of people like to stay up overnight just to tweet about Trump. This information seemed intriguing so we looked even deeper into this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tempTime.groupby('estTime')['entities.hashtags'].value_counts().nlargest(10).plot.bar()\n",
    "table = pd.pivot_table(tempTime, values = {\"entities.hashtags\"}, columns = {\"estTime\"}, aggfunc=\"count\")\n",
    "table.plot.bar(figsize = (10,5))\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Side note: We tried using pivot tables to combine the 4 time slots into a single bar graph. However, we would not find the keyword for aggfunc to give us only the top 5 hashtags of each time slot. It was only giving us ALL of the hashtags in each time slot and kept plotting all 24,820 hashtags into a single bar graph. So we decided to just leave them splitted and utilized the .nlargest() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mornings = mornings[mornings['entities.hashtags'] != \"\"]\n",
    "mornings['entities.hashtags'].value_counts().nlargest(5).plot.barh(fontsize = 15, figsize = (15,10)) #Morning (6am-11am)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the morning, 3 out of 5 trending hashtags about Trump were positive; Those being Trump, WomenforTrump, and VoteGold. Apparently there is a Twitter fan page called \"WomenForTrump\" that serves as a place for women, who support Trump, to converse.\n",
    "\n",
    "Only 2 out of 5 trending hashtags were negative towards Trump in the morning; Those being TeamJustice and NotMyChild. Apparently it looks like the Trump Administration was trying to push for schools to open and parents took it in a negative way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noon = noon[noon['entities.hashtags'] != \"\"]\n",
    "noon['entities.hashtags'].value_counts().nlargest(5).plot.barh(fontsize = 15, figsize = (15,10)) #Noon (11am-2pm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the noon, only 2 out of 5 trending hashtags about Trump were positive; Those being NEW and WomenforTrump. Apparently you are supposed to write #NEW to singal that your tweet is new...\n",
    "\n",
    "3 out of 5 trending hashtags were negative towards Trump in the noon; Those being NotMyChild, DemocratsStandTall and TrumpThreatensAmerica. Apparently Twitter thinks Trump in yet again threatening Americans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "night = night[night['entities.hashtags'] != \"\"]\n",
    "night['entities.hashtags'].value_counts().nlargest(5).plot.barh(fontsize = 15, figsize = (15,10)) #Night (6pm-12am)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At night, only 2 out of 5 trending hashtags about Trump were positive; Those being LandSlide2020, and Trump. Apparently #LandSlide2020 is talking about Trump's projected presidential votes and not an actual landslide somewhere in the mountains.\n",
    "\n",
    "3 out of 5 trending hashtags were negative towards Trump at night; Those being DemocratsStandTall, TrumpThreatensAmerica and Trump19. Apparently Americans have decided to rename COVID19 to TRUMP19 to show their... love... for how Trump handled the pandemic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overnight = overnight[overnight['entities.hashtags'] != \"\"]\n",
    "overnight['entities.hashtags'].value_counts().nlargest(5).plot.barh(fontsize = 15, figsize = (15,10)) #Overnight (12am-6am)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overnight, only 1 out of 5 trending hashtags about Trump were positive; Those being just Trump. Apparently putting your name after a hashtag shows support.\n",
    "\n",
    "4 out of 5 trending hashtags were negative towards Trump overnight; Those being DemocratsStandTall TrumpIsAloser, TrumpThreatensAmerica and Trump19. Apparently a lot of democrats like to stay up at night just to call for a Twitter uprising.\n",
    "\n",
    "\n",
    "This thorough analysis supports the idea that the type of trending hashtags that mentions Donald Trump changes throughout the day. Mainstream events that relates to the president directly or indirectly will also affect the outcome of trending Twitter hashtags. It is also interesting to note that the majority of democratic supporters can be found on the west coast, which is probably why night/overnight was dominated by negative comments towards Trump. At the end of the day, you can extrapolate some advice from this analysis; If you are a Republican, it is best to surf Twitter in the morning where a majority of supportive tweets can be found. However, if you are a democrat, you should wait until it is after dark before you speak strongly about President Trump."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsonData['user.verified'].value_counts().plot.pie(fontsize = 15, title= \"Verified Users\", figsize = (10,10), autopct = '%1.0f%%') #Delete if you don't need"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We were also interested in viewing the potential amount of people who can see these tweets. While not necessarily accurate to reflect how many people will see the tweet, followers on Twitter give at least an idea as to the potential amount of people these tweets can reach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x=jsonData[\"user.followers_count\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also see the most commonly used languages to communicate in the tweet with the hashtag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsonData['lang'].str.replace(\"en\", \"English\")\n",
    "jsonData['lang'].str.replace(\"es\", \"Spanish\")\n",
    "jsonData['lang'].str.replace(\"und\", \"Other\")\n",
    "jsonData['lang'].value_counts().plot.pie(fontsize = 15, title= \"Languages Used\", figsize = (10,10), autopct = '%1.0f%%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also see the common user locations, however these can be changed easily or spoofed via a VPN. It still gives an accurate view on where the Tweets are coming from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsonData['user.location'] = jsonData['user.location'].astype(str)\n",
    "dataLocs = jsonData[jsonData['user.location'] != 'None']\n",
    "mostcommonLoc = dataLocs['user.location'].value_counts()\n",
    "mostcommonLoc = mostcommonLoc.sort_values(ascending=False)\n",
    "mostcommonLoc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "mostcommonLoc.nlargest(23).plot.barh(fontsize = 15, figsize = (20,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also see just how many tweets the user has made overall, suggesting if the users tweeting about Trump are common \"tweeters\" or more infrequent \"tweeters\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x=jsonData[\"user.statuses_count\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
